{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2783f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e2b4be",
   "metadata": {},
   "source": [
    "V3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e141ce84",
   "metadata": {},
   "source": [
    "æœ€ä¼˜ç§€çš„ä¸€ç‰ˆç»“æœï¼š58.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c52fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ” YOLOv8 è·¯é¢ç¼ºé™·æ£€æµ‹æ¨ç†ç³»ç»Ÿï¼ˆä¼˜åŒ–ç‰ˆï¼‰\n",
      "======================================================================\n",
      "\n",
      "â³ æ­£åœ¨åŠ è½½æ¨¡å‹: D:\\43420\\Desktop\\åŒæµå¤§å­¦ç ”ä¸€ä¸Š\\äº¤é€šæ•°æ®åˆ†æä¸åº”ç”¨\\ç¬¬äºŒæ¬¡ä½œä¸š\\è·¯é¢ç—…å®³ä»»åŠ¡æ•°æ®é›†\\road_hazard_yolov8_finetune\\road_hazard_yolov8_finetune\\finetune_v3_unfrozen/weights/best.pt\n",
      "âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!\n",
      "\n",
      "ğŸ“Š æ¨ç†é…ç½®ï¼ˆå·²ä¼˜åŒ–ï¼‰:\n",
      "   å›¾åƒå°ºå¯¸: 1280px\n",
      "   ç½®ä¿¡åº¦é˜ˆå€¼: 4e-05 âœ… ä¼˜åŒ–\n",
      "   IoUé˜ˆå€¼: 0.655 âœ… ä¼˜åŒ–\n",
      "   TTA: ç¦ç”¨\n",
      "\n",
      "ğŸ“ æ‰¾åˆ° 462 å¼ éªŒè¯é›†å›¾ç‰‡\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ¨ç†è¿›è¡Œä¸­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462/462 [00:25<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœåˆ° submission3.json ...\n",
      "\n",
      "======================================================================\n",
      "âœ… æ¨ç†å®Œæˆ!\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:\n",
      "   å¤„ç†å›¾ç‰‡æ•°: 462\n",
      "   æ€»æ£€æµ‹æ¡†æ•°: 20220\n",
      "   å¹³å‡ç½®ä¿¡åº¦: 0.0269\n",
      "   æœ€é«˜ç½®ä¿¡åº¦: 0.9733\n",
      "   æœ€ä½ç½®ä¿¡åº¦: 0.0000\n",
      "\n",
      "ğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:\n",
      "   Pothole: 4625 ä¸ª (22.9%)\n",
      "   Net: 15595 ä¸ª (77.1%)\n",
      "\n",
      "ğŸ‰ ç»“æœå·²ä¿å­˜è‡³: submission3.json\n",
      "ğŸ’¡ ä¸‹ä¸€æ­¥: å°† submission3.json æäº¤åˆ°è¯„æµ‹å¹³å°\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# --- 1. ä¼˜åŒ–åçš„æ¨ç†é…ç½® ---\n",
    "CONFIG = {\n",
    "    # æ¨¡å‹è·¯å¾„\n",
    "    \"model_path\": \"D:\\\\43420\\\\Desktop\\\\åŒæµå¤§å­¦ç ”ä¸€ä¸Š\\\\äº¤é€šæ•°æ®åˆ†æä¸åº”ç”¨\\\\ç¬¬äºŒæ¬¡ä½œä¸š\\\\è·¯é¢ç—…å®³ä»»åŠ¡æ•°æ®é›†\\\\road_hazard_yolov8_finetune\\\\road_hazard_yolov8_finetune\\\\finetune_v3_unfrozen/weights/best.pt\",  # è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„\n",
    "    \"val_img_dir\": \"val\",                    # éªŒè¯é›†å›¾ç‰‡ç›®å½•\n",
    "    \"output_json\": \"submission3.json\",        # è¾“å‡ºJSONæ–‡ä»¶\n",
    "    \"device\": 0,                             # GPUç¼–å·ï¼ŒCPUç”¨'cpu'     \n",
    "    # âœ… ä¼˜åŒ–çš„æ¨ç†é…ç½®\n",
    "    \"img_size\": 1280,                        # æ¨ç†å›¾åƒå°ºå¯¸\n",
    "    \"conf_threshold\": 0.00004,                  # âœ… ä»0.001æ”¹ä¸º0.25ï¼ˆå‡å°‘å‡é˜³æ€§ï¼‰\n",
    "    \"iou_threshold\": 0.655,                   # âœ… ä»0.5æ”¹ä¸º0.65ï¼ˆæ›´ä¸¥æ ¼çš„NMSï¼‰\n",
    "    \n",
    "    # âœ… å¢å¼ºçš„TTAé…ç½®\n",
    "    \"use_tta\": False,                         # å¯ç”¨æµ‹è¯•æ—¶å¢å¼º\n",
    "    \"tta_scales\": [1.0],    # âœ… å¢åŠ 4ä¸ªå°ºåº¦ï¼ˆåŸä¸º3ä¸ªï¼‰\n",
    "    \"tta_flips\": [0, 1],                     # ç¿»è½¬ç±»å‹\n",
    "}\n",
    "\n",
    "# YOLOç±»åˆ«ç´¢å¼• -> COCO category_id çš„æ˜ å°„\n",
    "YOLO_TO_COCO = {\n",
    "    0: 1,  # Pothole -> 1\n",
    "    1: 2,  # Net -> 2\n",
    "}\n",
    "\n",
    "# --- 2. Weighted Boxes Fusion (WBF) å®ç° ---\n",
    "def weighted_boxes_fusion(boxes_list, scores_list, labels_list, \n",
    "                          iou_thr=0.55, skip_box_thr=0.0001):\n",
    "    \"\"\"\n",
    "    åŠ æƒæ¡†èåˆï¼ˆç”¨äºTTAå¤šä¸ªé¢„æµ‹ç»“æœèåˆï¼‰\n",
    "    æ¯”NMSæ›´æ™ºèƒ½çš„èåˆç­–ç•¥\n",
    "    \n",
    "    å‚æ•°:\n",
    "        boxes_list: list of arrays, æ¯ä¸ªarray shape=(N, 4), æ ¼å¼[x1,y1,x2,y2], å½’ä¸€åŒ–åæ ‡\n",
    "        scores_list: list of arrays, æ¯ä¸ªarray shape=(N,)\n",
    "        labels_list: list of arrays, æ¯ä¸ªarray shape=(N,)\n",
    "        iou_thr: IoUé˜ˆå€¼ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€ä¸ªç›®æ ‡\n",
    "        skip_box_thr: è·³è¿‡ç½®ä¿¡åº¦å¤ªä½çš„æ¡†\n",
    "    \n",
    "    è¿”å›:\n",
    "        boxes, scores, labels (èåˆåçš„ç»“æœ)\n",
    "    \"\"\"\n",
    "    if len(boxes_list) == 0:\n",
    "        return np.zeros((0, 4)), np.zeros(0), np.zeros(0)\n",
    "    \n",
    "    # åˆå¹¶æ‰€æœ‰é¢„æµ‹\n",
    "    all_boxes = []\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for boxes, scores, labels in zip(boxes_list, scores_list, labels_list):\n",
    "        if len(boxes) > 0:\n",
    "            all_boxes.append(boxes)\n",
    "            all_scores.append(scores)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    if len(all_boxes) == 0:\n",
    "        return np.zeros((0, 4)), np.zeros(0), np.zeros(0)\n",
    "    \n",
    "    all_boxes = np.vstack(all_boxes)\n",
    "    all_scores = np.hstack(all_scores)\n",
    "    all_labels = np.hstack(all_labels)\n",
    "    \n",
    "    # æŒ‰ç±»åˆ«åˆ†åˆ«å¤„ç†\n",
    "    unique_labels = np.unique(all_labels)\n",
    "    fused_boxes = []\n",
    "    fused_scores = []\n",
    "    fused_labels = []\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        mask = all_labels == label\n",
    "        class_boxes = all_boxes[mask]\n",
    "        class_scores = all_scores[mask]\n",
    "        \n",
    "        # æŒ‰åˆ†æ•°æ’åº\n",
    "        order = class_scores.argsort()[::-1]\n",
    "        class_boxes = class_boxes[order]\n",
    "        class_scores = class_scores[order]\n",
    "        \n",
    "        # WBFæ ¸å¿ƒç®—æ³•\n",
    "        while len(class_boxes) > 0:\n",
    "            # å–æœ€é«˜åˆ†çš„æ¡†\n",
    "            best_box = class_boxes[0:1]\n",
    "            best_score = class_scores[0:1]\n",
    "            \n",
    "            # è®¡ç®—ä¸å…¶ä»–æ¡†çš„IoU\n",
    "            if len(class_boxes) > 1:\n",
    "                ious = compute_iou_vectorized(best_box, class_boxes[1:])\n",
    "                \n",
    "                # æ‰¾åˆ°é«˜IoUçš„æ¡†è¿›è¡Œèåˆ\n",
    "                merge_mask = ious >= iou_thr\n",
    "                merge_indices = np.where(merge_mask)[0] + 1\n",
    "                \n",
    "                if len(merge_indices) > 0:\n",
    "                    # åŠ æƒå¹³å‡æ¡†åæ ‡\n",
    "                    merge_boxes = class_boxes[np.concatenate([[0], merge_indices])]\n",
    "                    merge_scores = class_scores[np.concatenate([[0], merge_indices])]\n",
    "                    \n",
    "                    weights = merge_scores / merge_scores.sum()\n",
    "                    fused_box = (merge_boxes * weights[:, None]).sum(axis=0)\n",
    "                    fused_score = merge_scores.mean()  # å¹³å‡ç½®ä¿¡åº¦\n",
    "                    \n",
    "                    fused_boxes.append(fused_box)\n",
    "                    fused_scores.append(fused_score)\n",
    "                    fused_labels.append(label)\n",
    "                    \n",
    "                    # ç§»é™¤å·²èåˆçš„æ¡†\n",
    "                    keep_mask = np.ones(len(class_boxes), dtype=bool)\n",
    "                    keep_mask[0] = False\n",
    "                    keep_mask[merge_indices] = False\n",
    "                    class_boxes = class_boxes[keep_mask]\n",
    "                    class_scores = class_scores[keep_mask]\n",
    "                else:\n",
    "                    # æ²¡æœ‰é‡å çš„æ¡†ï¼Œå•ç‹¬ä¿ç•™\n",
    "                    fused_boxes.append(best_box[0])\n",
    "                    fused_scores.append(best_score[0])\n",
    "                    fused_labels.append(label)\n",
    "                    class_boxes = class_boxes[1:]\n",
    "                    class_scores = class_scores[1:]\n",
    "            else:\n",
    "                # åªå‰©æœ€åä¸€ä¸ªæ¡†\n",
    "                fused_boxes.append(best_box[0])\n",
    "                fused_scores.append(best_score[0])\n",
    "                fused_labels.append(label)\n",
    "                break\n",
    "    \n",
    "    if len(fused_boxes) > 0:\n",
    "        return (np.array(fused_boxes), \n",
    "                np.array(fused_scores), \n",
    "                np.array(fused_labels))\n",
    "    else:\n",
    "        return np.zeros((0, 4)), np.zeros(0), np.zeros(0)\n",
    "\n",
    "def compute_iou_vectorized(box, boxes):\n",
    "    \"\"\"å‘é‡åŒ–è®¡ç®—IoUï¼ˆIntersection over Unionï¼‰\"\"\"\n",
    "    x1 = np.maximum(box[0, 0], boxes[:, 0])\n",
    "    y1 = np.maximum(box[0, 1], boxes[:, 1])\n",
    "    x2 = np.minimum(box[0, 2], boxes[:, 2])\n",
    "    y2 = np.minimum(box[0, 3], boxes[:, 3])\n",
    "    \n",
    "    # äº¤é›†é¢ç§¯\n",
    "    intersection = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "    \n",
    "    # å¹¶é›†é¢ç§¯\n",
    "    box_area = (box[0, 2] - box[0, 0]) * (box[0, 3] - box[0, 1])\n",
    "    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union = box_area + boxes_area - intersection\n",
    "    \n",
    "    return intersection / (union + 1e-6)\n",
    "\n",
    "# --- 3. TTAæ¨ç†ï¼ˆä½¿ç”¨WBFèåˆï¼‰---\n",
    "def predict_with_tta(model, image_path, scales, flips, img_size, conf_threshold, iou_threshold):\n",
    "    \"\"\"\n",
    "    æµ‹è¯•æ—¶å¢å¼ºé¢„æµ‹\n",
    "    ä½¿ç”¨å¤šå°ºåº¦å’Œç¿»è½¬ï¼Œæœ€åç”¨WBFèåˆç»“æœ\n",
    "    \n",
    "    å‚æ•°:\n",
    "        model: YOLOæ¨¡å‹\n",
    "        image_path: å›¾ç‰‡è·¯å¾„\n",
    "        scales: ç¼©æ”¾å°ºåº¦åˆ—è¡¨ [0.8, 1.0, 1.2, 1.4]\n",
    "        flips: ç¿»è½¬ç±»å‹åˆ—è¡¨ [0=ä¸ç¿»è½¬, 1=æ°´å¹³ç¿»è½¬]\n",
    "        img_size: æ¨ç†å°ºå¯¸\n",
    "        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼\n",
    "        iou_threshold: NMS IoUé˜ˆå€¼\n",
    "    \n",
    "    è¿”å›:\n",
    "        boxes, scores, labels (numpy arrays, ç»å¯¹åæ ‡)\n",
    "    \"\"\"\n",
    "    # è¯»å–åŸå§‹å›¾ç‰‡\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    all_boxes_list = []\n",
    "    all_scores_list = []\n",
    "    all_labels_list = []\n",
    "    \n",
    "    # éå†æ‰€æœ‰å°ºåº¦å’Œç¿»è½¬ç»„åˆ\n",
    "    for scale in scales:\n",
    "        for flip in flips:\n",
    "            # å‡†å¤‡å›¾ç‰‡\n",
    "            test_img = img.copy()\n",
    "            \n",
    "            # æ°´å¹³ç¿»è½¬\n",
    "            if flip == 1:\n",
    "                test_img = cv2.flip(test_img, 1)\n",
    "            \n",
    "            # ç¼©æ”¾\n",
    "            if scale != 1.0:\n",
    "                new_h, new_w = int(h * scale), int(w * scale)\n",
    "                test_img = cv2.resize(test_img, (new_w, new_h))\n",
    "            \n",
    "            # æ¨ç†\n",
    "            results = model.predict(\n",
    "                test_img,\n",
    "                imgsz=img_size,\n",
    "                conf=conf_threshold,\n",
    "                iou=iou_threshold,\n",
    "                verbose=False,\n",
    "                device=CONFIG['device']\n",
    "            )[0]\n",
    "            \n",
    "            if len(results.boxes) == 0:\n",
    "                continue\n",
    "            \n",
    "            # æå–æ£€æµ‹ç»“æœ\n",
    "            boxes = results.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]\n",
    "            scores = results.boxes.conf.cpu().numpy()\n",
    "            labels = results.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            # åæ ‡è¿˜åŸï¼ˆç¼©æ”¾ï¼‰\n",
    "            if scale != 1.0:\n",
    "                boxes /= scale\n",
    "            \n",
    "            # åæ ‡è¿˜åŸï¼ˆç¿»è½¬ï¼‰\n",
    "            if flip == 1:\n",
    "                boxes[:, [0, 2]] = w - boxes[:, [2, 0]]\n",
    "            \n",
    "            # è½¬æ¢ä¸ºå½’ä¸€åŒ–åæ ‡ï¼ˆç”¨äºWBFï¼‰\n",
    "            norm_boxes = boxes.copy()\n",
    "            norm_boxes[:, [0, 2]] /= w\n",
    "            norm_boxes[:, [1, 3]] /= h\n",
    "            norm_boxes = np.clip(norm_boxes, 0, 1)\n",
    "            \n",
    "            all_boxes_list.append(norm_boxes)\n",
    "            all_scores_list.append(scores)\n",
    "            all_labels_list.append(labels)\n",
    "    \n",
    "    # ä½¿ç”¨WBFèåˆæ‰€æœ‰é¢„æµ‹\n",
    "    if len(all_boxes_list) > 0:\n",
    "        fused_boxes, fused_scores, fused_labels = weighted_boxes_fusion(\n",
    "            all_boxes_list, \n",
    "            all_scores_list, \n",
    "            all_labels_list,\n",
    "            iou_thr=0.55,\n",
    "            skip_box_thr=0.0001\n",
    "        )\n",
    "        \n",
    "        # åå½’ä¸€åŒ–åæ ‡ï¼ˆæ¢å¤ä¸ºç»å¯¹åæ ‡ï¼‰\n",
    "        if len(fused_boxes) > 0:\n",
    "            fused_boxes[:, [0, 2]] *= w\n",
    "            fused_boxes[:, [1, 3]] *= h\n",
    "        \n",
    "        return fused_boxes, fused_scores, fused_labels\n",
    "    else:\n",
    "        return np.zeros((0, 4)), np.zeros(0), np.zeros(0)\n",
    "\n",
    "# --- 4. æ ‡å‡†æ¨ç†ï¼ˆæ— TTAï¼‰---\n",
    "def predict_standard(model, image_path, img_size, conf_threshold, iou_threshold):\n",
    "    \"\"\"æ ‡å‡†æ¨ç†ï¼ˆä¸ä½¿ç”¨TTAï¼Œé€Ÿåº¦å¿«ï¼‰\"\"\"\n",
    "    results = model.predict(\n",
    "        str(image_path),\n",
    "        imgsz=img_size,\n",
    "        conf=conf_threshold,\n",
    "        iou=iou_threshold,\n",
    "        verbose=False,\n",
    "        device=CONFIG['device']\n",
    "    )[0]\n",
    "    \n",
    "    if len(results.boxes) == 0:\n",
    "        return np.zeros((0, 4)), np.zeros(0), np.zeros(0)\n",
    "    \n",
    "    boxes = results.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]\n",
    "    scores = results.boxes.conf.cpu().numpy()\n",
    "    labels = results.boxes.cls.cpu().numpy().astype(int)\n",
    "    \n",
    "    return boxes, scores, labels\n",
    "\n",
    "# --- 5. ä¸»æ¨ç†å‡½æ•° ---\n",
    "def generate_submission_file():\n",
    "    \"\"\"ç”Ÿæˆæäº¤æ–‡ä»¶\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ” YOLOv8 è·¯é¢ç¼ºé™·æ£€æµ‹æ¨ç†ç³»ç»Ÿï¼ˆä¼˜åŒ–ç‰ˆï¼‰\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶\n",
    "    if not Path(CONFIG['model_path']).exists():\n",
    "        print(f\"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {CONFIG['model_path']}\")\n",
    "        print(f\"ğŸ’¡ æç¤º: è¯·å…ˆè¿è¡Œ train_yolov8_optimized.py è®­ç»ƒæ¨¡å‹\")\n",
    "        return\n",
    "    \n",
    "    # æ£€æŸ¥éªŒè¯é›†ç›®å½•\n",
    "    if not Path(CONFIG['val_img_dir']).exists():\n",
    "        print(f\"âŒ é”™è¯¯: éªŒè¯é›†ç›®å½•ä¸å­˜åœ¨ {CONFIG['val_img_dir']}\")\n",
    "        return\n",
    "    \n",
    "    # åŠ è½½æ¨¡å‹\n",
    "    print(f\"â³ æ­£åœ¨åŠ è½½æ¨¡å‹: {CONFIG['model_path']}\")\n",
    "    model = YOLO(CONFIG['model_path'])\n",
    "    print(f\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!\\n\")\n",
    "    \n",
    "    # æ‰“å°é…ç½®ä¿¡æ¯\n",
    "    print(f\"ğŸ“Š æ¨ç†é…ç½®ï¼ˆå·²ä¼˜åŒ–ï¼‰:\")\n",
    "    print(f\"   å›¾åƒå°ºå¯¸: {CONFIG['img_size']}px\")\n",
    "    print(f\"   ç½®ä¿¡åº¦é˜ˆå€¼: {CONFIG['conf_threshold']} âœ… ä¼˜åŒ–\")\n",
    "    print(f\"   IoUé˜ˆå€¼: {CONFIG['iou_threshold']} âœ… ä¼˜åŒ–\")\n",
    "    print(f\"   TTA: {'å¯ç”¨' if CONFIG['use_tta'] else 'ç¦ç”¨'}\")\n",
    "    if CONFIG['use_tta']:\n",
    "        print(f\"   TTAå°ºåº¦: {CONFIG['tta_scales']} âœ… å¢åŠ \")\n",
    "        print(f\"   TTAç¿»è½¬: {CONFIG['tta_flips']}\")\n",
    "    print()\n",
    "    \n",
    "    # è·å–éªŒè¯é›†å›¾ç‰‡åˆ—è¡¨\n",
    "    val_dir = Path(CONFIG['val_img_dir'])\n",
    "    image_files = list(val_dir.glob(\"*.jpg\")) + \\\n",
    "                  list(val_dir.glob(\"*.png\")) + \\\n",
    "                  list(val_dir.glob(\"*.jpeg\"))\n",
    "    \n",
    "    print(f\"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ éªŒè¯é›†å›¾ç‰‡\\n\")\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"âš ï¸ è­¦å‘Š: éªŒè¯é›†ç›®å½•ä¸ºç©º\")\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # æ¨ç†å¾ªç¯\n",
    "    for img_path in tqdm(image_files, desc=\"ğŸš€ æ¨ç†è¿›è¡Œä¸­\"):\n",
    "        try:\n",
    "            # é€‰æ‹©æ¨ç†æ–¹å¼\n",
    "            if CONFIG['use_tta']:\n",
    "                boxes, scores, labels = predict_with_tta(\n",
    "                    model,\n",
    "                    img_path,\n",
    "                    scales=CONFIG['tta_scales'],\n",
    "                    flips=CONFIG['tta_flips'],\n",
    "                    img_size=CONFIG['img_size'],\n",
    "                    conf_threshold=CONFIG['conf_threshold'],\n",
    "                    iou_threshold=CONFIG['iou_threshold']\n",
    "                )\n",
    "            else:\n",
    "                boxes, scores, labels = predict_standard(\n",
    "                    model,\n",
    "                    img_path,\n",
    "                    img_size=CONFIG['img_size'],\n",
    "                    conf_threshold=CONFIG['conf_threshold'],\n",
    "                    iou_threshold=CONFIG['iou_threshold']\n",
    "                )\n",
    "            \n",
    "            # è½¬æ¢ä¸ºCOCOæ ¼å¼å¹¶ä¿å­˜ç»“æœ\n",
    "            for i in range(len(boxes)):\n",
    "                x1, y1, x2, y2 = boxes[i]\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                \n",
    "                # è½¬æ¢YOLOç±»åˆ«ç´¢å¼•ä¸ºCOCO category_id\n",
    "                coco_category_id = YOLO_TO_COCO.get(int(labels[i]), int(labels[i]))\n",
    "                \n",
    "                results.append({\n",
    "                    \"bbox\": [float(x1), float(y1), float(width), float(height)],\n",
    "                    \"category_id\": coco_category_id,\n",
    "                    \"file_name\": img_path.name,\n",
    "                    \"score\": float(scores[i])\n",
    "                })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸ å¤„ç†å›¾ç‰‡ {img_path.name} æ—¶å‡ºé”™: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # ä¿å­˜æ¨ç†ç»“æœ\n",
    "    print(f\"\\nğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœåˆ° {CONFIG['output_json']} ...\")\n",
    "    with open(CONFIG['output_json'], 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"âœ… æ¨ç†å®Œæˆ!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "    print(f\"   å¤„ç†å›¾ç‰‡æ•°: {len(image_files)}\")\n",
    "    print(f\"   æ€»æ£€æµ‹æ¡†æ•°: {len(results)}\")\n",
    "    \n",
    "    if len(results) > 0:\n",
    "        scores = [r['score'] for r in results]\n",
    "        print(f\"   å¹³å‡ç½®ä¿¡åº¦: {np.mean(scores):.4f}\")\n",
    "        print(f\"   æœ€é«˜ç½®ä¿¡åº¦: {np.max(scores):.4f}\")\n",
    "        print(f\"   æœ€ä½ç½®ä¿¡åº¦: {np.min(scores):.4f}\")\n",
    "        \n",
    "        # æŒ‰ç±»åˆ«ç»Ÿè®¡\n",
    "        category_counts = {}\n",
    "        for r in results:\n",
    "            cat_id = r['category_id']\n",
    "            category_counts[cat_id] = category_counts.get(cat_id, 0) + 1\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:\")\n",
    "        category_names = {1: \"Pothole\", 2: \"Net\"}\n",
    "        for cat_id, count in sorted(category_counts.items()):\n",
    "            cat_name = category_names.get(cat_id, f\"Class {cat_id}\")\n",
    "            percentage = (count / len(results)) * 100\n",
    "            print(f\"   {cat_name}: {count} ä¸ª ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ ç»“æœå·²ä¿å­˜è‡³: {CONFIG['output_json']}\")\n",
    "    print(f\"ğŸ’¡ ä¸‹ä¸€æ­¥: å°† {CONFIG['output_json']} æäº¤åˆ°è¯„æµ‹å¹³å°\")\n",
    "\n",
    "# --- 6. è¿è¡Œå…¥å£ ---\n",
    "if __name__ == \"__main__\":\n",
    "    generate_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70709640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ” YOLOv8 è·¯é¢ç¼ºé™·æ£€æµ‹æ¨ç†ç³»ç»Ÿï¼ˆä¼˜åŒ–ç‰ˆï¼‰\n",
      "======================================================================\n",
      "\n",
      "â³ æ­£åœ¨åŠ è½½æ¨¡å‹: D:\\43420\\Desktop\\åŒæµå¤§å­¦ç ”ä¸€ä¸Š\\äº¤é€šæ•°æ®åˆ†æä¸åº”ç”¨\\ç¬¬äºŒæ¬¡ä½œä¸š\\è·¯é¢ç—…å®³ä»»åŠ¡æ•°æ®é›†\\road_hazard_yolov8_finetune\\road_hazard_yolov8_finetune\\finetune_v3_unfrozen/weights/best.pt\n",
      "âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!\n",
      "\n",
      "ğŸ“Š æ¨ç†é…ç½®ï¼ˆå·²ä¼˜åŒ–ï¼‰:\n",
      "   å›¾åƒå°ºå¯¸: 1280px\n",
      "   ç½®ä¿¡åº¦é˜ˆå€¼: 4e-05 âœ… ä¼˜åŒ–\n",
      "   IoUé˜ˆå€¼: 0.659 âœ… ä¼˜åŒ–\n",
      "   TTA: ç¦ç”¨\n",
      "\n",
      "ğŸ“ æ‰¾åˆ° 462 å¼ éªŒè¯é›†å›¾ç‰‡\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ¨ç†è¿›è¡Œä¸­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462/462 [00:24<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœåˆ° submission3.json ...\n",
      "\n",
      "======================================================================\n",
      "âœ… æ¨ç†å®Œæˆ!\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:\n",
      "   å¤„ç†å›¾ç‰‡æ•°: 462\n",
      "   æ€»æ£€æµ‹æ¡†æ•°: 20473\n",
      "   å¹³å‡ç½®ä¿¡åº¦: 0.0266\n",
      "   æœ€é«˜ç½®ä¿¡åº¦: 0.9733\n",
      "   æœ€ä½ç½®ä¿¡åº¦: 0.0000\n",
      "\n",
      "ğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:\n",
      "   Pothole: 4646 ä¸ª (22.7%)\n",
      "   Net: 15827 ä¸ª (77.3%)\n",
      "\n",
      "ğŸ‰ ç»“æœå·²ä¿å­˜è‡³: submission3.json\n",
      "ğŸ’¡ ä¸‹ä¸€æ­¥: å°† submission3.json æäº¤åˆ°è¯„æµ‹å¹³å°\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# --- 1. ä¼˜åŒ–åçš„æ¨ç†é…ç½® ---\n",
    "CONFIG = {\n",
    "    # æ¨¡å‹è·¯å¾„\n",
    "    \"model_path\": \"D:\\\\43420\\\\Desktop\\\\åŒæµå¤§å­¦ç ”ä¸€ä¸Š\\\\äº¤é€šæ•°æ®åˆ†æä¸åº”ç”¨\\\\ç¬¬äºŒæ¬¡ä½œä¸š\\\\è·¯é¢ç—…å®³ä»»åŠ¡æ•°æ®é›†\\\\road_hazard_yolov8_finetune\\\\road_hazard_yolov8_finetune\\\\finetune_v3_unfrozen/weights/best.pt\",  # è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„\n",
    "    \"val_img_dir\": \"val\",                    # éªŒè¯é›†å›¾ç‰‡ç›®å½•\n",
    "    \"output_json\": \"submission3.json\",        # è¾“å‡ºJSONæ–‡ä»¶\n",
    "    \"device\": 0,                             # GPUç¼–å·ï¼ŒCPUç”¨'cpu'     \n",
    "    # âœ… ä¼˜åŒ–çš„æ¨ç†é…ç½®\n",
    "    \"img_size\": 1280,                        # æ¨ç†å›¾åƒå°ºå¯¸\n",
    "    \"conf_threshold\": 0.00004,                  # âœ… ä»0.001æ”¹ä¸º0.25ï¼ˆå‡å°‘å‡é˜³æ€§ï¼‰\n",
    "    \"iou_threshold\": 0.659,                   # âœ… ä»0.5æ”¹ä¸º0.65ï¼ˆæ›´ä¸¥æ ¼çš„NMSï¼‰\n",
    "    \n",
    "    # âœ… å¢å¼ºçš„TTAé…ç½®\n",
    "    \"use_tta\": False,                         # å¯ç”¨æµ‹è¯•æ—¶å¢å¼º\n",
    "    \"tta_scales\": [1.0],    # âœ… å¢åŠ 4ä¸ªå°ºåº¦ï¼ˆåŸä¸º3ä¸ªï¼‰\n",
    "    \"tta_flips\": [0],                     # ç¿»è½¬ç±»å‹\n",
    "}\n",
    "\n",
    "# YOLOç±»åˆ«ç´¢å¼• -> COCO category_id çš„æ˜ å°„\n",
    "YOLO_TO_COCO = {\n",
    "    0: 1,  # Pothole -> 1\n",
    "    1: 2,  # Net -> 2\n",
    "}\n",
    "\n",
    "# --- 2. Weighted Boxes Fusion (WBF) å®ç° ---\n",
    "def weighted_boxes_fusion(boxes_list, scores_list, labels_list, \n",
    "                          iou_thr=0.55, skip_box_thr=0.0001):\n",
    "    \"\"\"\n",
    "    åŠ æƒæ¡†èåˆï¼ˆç”¨äºTTAå¤šä¸ªé¢„æµ‹ç»“æœèåˆï¼‰\n",
    "    æ¯”NMSæ›´æ™ºèƒ½çš„èåˆç­–ç•¥\n",
    "    \n",
    "    å‚æ•°:\n",
    "        boxes_list: list of arrays, æ¯ä¸ªarray shape=(N, 4), æ ¼å¼[x1,y1,x2,y2], å½’ä¸€åŒ–åæ ‡\n",
    "        scores_list: list of arrays, æ¯ä¸ªarray shape=(N,)\n",
    "        labels_list: list of arrays, æ¯ä¸ªarray shape=(N,)\n",
    "        iou_thr: IoUé˜ˆå€¼ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€ä¸ªç›®æ ‡\n",
    "        skip_box_thr: è·³è¿‡ç½®ä¿¡åº¦å¤ªä½çš„æ¡†\n",
    "    \n",
    "    è¿”å›:\n",
    "        boxes, scores, labels (èåˆåçš„ç»“æœ)\n",
    "    \"\"\"\n",
    "    if len(boxes_list) == 0:\n",
    "        return np.zeros((0, 4)), np.zeros(0), np.zeros(0)\n",
    "    \n",
    "    # åˆå¹¶æ‰€æœ‰é¢„æµ‹\n",
    "    all_boxes = []\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for boxes, scores, labels in zip(boxes_list, scores_list, labels_list):\n",
    "        if len(boxes) > 0:\n",
    "            all_boxes.append(boxes)\n",
    "            all_scores.append(scores)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    if len(all_boxes) == 0:\n",
    "        return np.zeros((0, 4)), np.zeros(0), np.zeros(0)\n",
    "    \n",
    "    all_boxes = np.vstack(all_boxes)\n",
    "    all_scores = np.hstack(all_scores)\n",
    "    all_labels = np.hstack(all_labels)\n",
    "    \n",
    "    # æŒ‰ç±»åˆ«åˆ†åˆ«å¤„ç†\n",
    "    unique_labels = np.unique(all_labels)\n",
    "    fused_boxes = []\n",
    "    fused_scores = []\n",
    "    fused_labels = []\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        mask = all_labels == label\n",
    "        class_boxes = all_boxes[mask]\n",
    "        class_scores = all_scores[mask]\n",
    "        \n",
    "        # æŒ‰åˆ†æ•°æ’åº\n",
    "        order = class_scores.argsort()[::-1]\n",
    "        class_boxes = class_boxes[order]\n",
    "        class_scores = class_scores[order]\n",
    "        \n",
    "        # WBFæ ¸å¿ƒç®—æ³•\n",
    "        while len(class_boxes) > 0:\n",
    "            # å–æœ€é«˜åˆ†çš„æ¡†\n",
    "            best_box = class_boxes[0:1]\n",
    "            best_score = class_scores[0:1]\n",
    "            \n",
    "            # è®¡ç®—ä¸å…¶ä»–æ¡†çš„IoU\n",
    "            if len(class_boxes) > 1:\n",
    "                ious = compute_iou_vectorized(best_box, class_boxes[1:])\n",
    "                \n",
    "                # æ‰¾åˆ°é«˜IoUçš„æ¡†è¿›è¡Œèåˆ\n",
    "                merge_mask = ious >= iou_thr\n",
    "                merge_indices = np.where(merge_mask)[0] + 1\n",
    "                \n",
    "                if len(merge_indices) > 0:\n",
    "                    # åŠ æƒå¹³å‡æ¡†åæ ‡\n",
    "                    merge_boxes = class_boxes[np.concatenate([[0], merge_indices])]\n",
    "                    merge_scores = class_scores[np.concatenate([[0], merge_indices])]\n",
    "                    \n",
    "                    weights = merge_scores / merge_scores.sum()\n",
    "                    fused_box = (merge_boxes * weights[:, None]).sum(axis=0)\n",
    "                    fused_score = merge_scores.mean()  # å¹³å‡ç½®ä¿¡åº¦\n",
    "                    \n",
    "                    fused_boxes.append(fused_box)\n",
    "                    fused_scores.append(fused_score)\n",
    "                    fused_labels.append(label)\n",
    "                    \n",
    "                    # ç§»é™¤å·²èåˆçš„æ¡†\n",
    "                    keep_mask = np.ones(len(class_boxes), dtype=bool)\n",
    "                    keep_mask[0] = False\n",
    "                    keep_mask[merge_indices] = False\n",
    "                    class_boxes = class_boxes[keep_mask]\n",
    "                    class_scores = class_scores[keep_mask]\n",
    "                else:\n",
    "                    # æ²¡æœ‰é‡å çš„æ¡†ï¼Œå•ç‹¬ä¿ç•™\n",
    "                    fused_boxes.append(best_box[0])\n",
    "                    fused_scores.append(best_score[0])\n",
    "                    fused_labels.append(label)\n",
    "                    class_boxes = class_boxes[1:]\n",
    "                    class_scores = class_scores[1:]\n",
    "            else:\n",
    "                # åªå‰©æœ€åä¸€ä¸ªæ¡†\n",
    "                fused_boxes.append(best_box[0])\n",
    "                fused_scores.append(best_score[0])\n",
    "                fused_labels.append(label)\n",
    "                break\n",
    "    \n",
    "    if len(fused_boxes) > 0:\n",
    "        return (np.array(fused_boxes), \n",
    "                np.array(fused_scores), \n",
    "                np.array(fused_labels))\n",
    "    else:\n",
    "        return np.zeros((0, 4)), np.zeros(0), np.zeros(0)\n",
    "\n",
    "def compute_iou_vectorized(box, boxes):\n",
    "    \"\"\"å‘é‡åŒ–è®¡ç®—IoUï¼ˆIntersection over Unionï¼‰\"\"\"\n",
    "    x1 = np.maximum(box[0, 0], boxes[:, 0])\n",
    "    y1 = np.maximum(box[0, 1], boxes[:, 1])\n",
    "    x2 = np.minimum(box[0, 2], boxes[:, 2])\n",
    "    y2 = np.minimum(box[0, 3], boxes[:, 3])\n",
    "    \n",
    "    # äº¤é›†é¢ç§¯\n",
    "    intersection = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "    \n",
    "    # å¹¶é›†é¢ç§¯\n",
    "    box_area = (box[0, 2] - box[0, 0]) * (box[0, 3] - box[0, 1])\n",
    "    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union = box_area + boxes_area - intersection\n",
    "    \n",
    "    return intersection / (union + 1e-6)\n",
    "\n",
    "# --- 3. TTAæ¨ç†ï¼ˆä½¿ç”¨WBFèåˆï¼‰---\n",
    "def predict_with_tta(model, image_path, scales, flips, img_size, conf_threshold, iou_threshold):\n",
    "    \"\"\"\n",
    "    æµ‹è¯•æ—¶å¢å¼ºé¢„æµ‹\n",
    "    ä½¿ç”¨å¤šå°ºåº¦å’Œç¿»è½¬ï¼Œæœ€åç”¨WBFèåˆç»“æœ\n",
    "    \n",
    "    å‚æ•°:\n",
    "        model: YOLOæ¨¡å‹\n",
    "        image_path: å›¾ç‰‡è·¯å¾„\n",
    "        scales: ç¼©æ”¾å°ºåº¦åˆ—è¡¨ [0.8, 1.0, 1.2, 1.4]\n",
    "        flips: ç¿»è½¬ç±»å‹åˆ—è¡¨ [0=ä¸ç¿»è½¬, 1=æ°´å¹³ç¿»è½¬]\n",
    "        img_size: æ¨ç†å°ºå¯¸\n",
    "        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼\n",
    "        iou_threshold: NMS IoUé˜ˆå€¼\n",
    "    \n",
    "    è¿”å›:\n",
    "        boxes, scores, labels (numpy arrays, ç»å¯¹åæ ‡)\n",
    "    \"\"\"\n",
    "    # è¯»å–åŸå§‹å›¾ç‰‡\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    all_boxes_list = []\n",
    "    all_scores_list = []\n",
    "    all_labels_list = []\n",
    "    \n",
    "    # éå†æ‰€æœ‰å°ºåº¦å’Œç¿»è½¬ç»„åˆ\n",
    "    for scale in scales:\n",
    "        for flip in flips:\n",
    "            # å‡†å¤‡å›¾ç‰‡\n",
    "            test_img = img.copy()\n",
    "            \n",
    "            # æ°´å¹³ç¿»è½¬\n",
    "            if flip == 1:\n",
    "                test_img = cv2.flip(test_img, 1)\n",
    "            \n",
    "            # ç¼©æ”¾\n",
    "            if scale != 1.0:\n",
    "                new_h, new_w = int(h * scale), int(w * scale)\n",
    "                test_img = cv2.resize(test_img, (new_w, new_h))\n",
    "            \n",
    "            # æ¨ç†\n",
    "            results = model.predict(\n",
    "                test_img,\n",
    "                imgsz=img_size,\n",
    "                conf=conf_threshold,\n",
    "                iou=iou_threshold,\n",
    "                verbose=False,\n",
    "                device=CONFIG['device']\n",
    "            )[0]\n",
    "            \n",
    "            if len(results.boxes) == 0:\n",
    "                continue\n",
    "            \n",
    "            # æå–æ£€æµ‹ç»“æœ\n",
    "            boxes = results.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]\n",
    "            scores = results.boxes.conf.cpu().numpy()\n",
    "            labels = results.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            # åæ ‡è¿˜åŸï¼ˆç¼©æ”¾ï¼‰\n",
    "            if scale != 1.0:\n",
    "                boxes /= scale\n",
    "            \n",
    "            # åæ ‡è¿˜åŸï¼ˆç¿»è½¬ï¼‰\n",
    "            if flip == 1:\n",
    "                boxes[:, [0, 2]] = w - boxes[:, [2, 0]]\n",
    "            \n",
    "            # è½¬æ¢ä¸ºå½’ä¸€åŒ–åæ ‡ï¼ˆç”¨äºWBFï¼‰\n",
    "            norm_boxes = boxes.copy()\n",
    "            norm_boxes[:, [0, 2]] /= w\n",
    "            norm_boxes[:, [1, 3]] /= h\n",
    "            norm_boxes = np.clip(norm_boxes, 0, 1)\n",
    "            \n",
    "            all_boxes_list.append(norm_boxes)\n",
    "            all_scores_list.append(scores)\n",
    "            all_labels_list.append(labels)\n",
    "    \n",
    "    # ä½¿ç”¨WBFèåˆæ‰€æœ‰é¢„æµ‹\n",
    "    if len(all_boxes_list) > 0:\n",
    "        fused_boxes, fused_scores, fused_labels = weighted_boxes_fusion(\n",
    "            all_boxes_list, \n",
    "            all_scores_list, \n",
    "            all_labels_list,\n",
    "            iou_thr=0.55,\n",
    "            skip_box_thr=0.0001\n",
    "        )\n",
    "        \n",
    "        # åå½’ä¸€åŒ–åæ ‡ï¼ˆæ¢å¤ä¸ºç»å¯¹åæ ‡ï¼‰\n",
    "        if len(fused_boxes) > 0:\n",
    "            fused_boxes[:, [0, 2]] *= w\n",
    "            fused_boxes[:, [1, 3]] *= h\n",
    "        \n",
    "        return fused_boxes, fused_scores, fused_labels\n",
    "    else:\n",
    "        return np.zeros((0, 4)), np.zeros(0), np.zeros(0)\n",
    "\n",
    "# --- 4. æ ‡å‡†æ¨ç†ï¼ˆæ— TTAï¼‰---\n",
    "def predict_standard(model, image_path, img_size, conf_threshold, iou_threshold):\n",
    "    \"\"\"æ ‡å‡†æ¨ç†ï¼ˆä¸ä½¿ç”¨TTAï¼Œé€Ÿåº¦å¿«ï¼‰\"\"\"\n",
    "    results = model.predict(\n",
    "        str(image_path),\n",
    "        imgsz=img_size,\n",
    "        conf=conf_threshold,\n",
    "        iou=iou_threshold,\n",
    "        verbose=False,\n",
    "        device=CONFIG['device']\n",
    "    )[0]\n",
    "    \n",
    "    if len(results.boxes) == 0:\n",
    "        return np.zeros((0, 4)), np.zeros(0), np.zeros(0)\n",
    "    \n",
    "    boxes = results.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]\n",
    "    scores = results.boxes.conf.cpu().numpy()\n",
    "    labels = results.boxes.cls.cpu().numpy().astype(int)\n",
    "    \n",
    "    return boxes, scores, labels\n",
    "\n",
    "# --- 5. ä¸»æ¨ç†å‡½æ•° ---\n",
    "def generate_submission_file():\n",
    "    \"\"\"ç”Ÿæˆæäº¤æ–‡ä»¶\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ” YOLOv8 è·¯é¢ç¼ºé™·æ£€æµ‹æ¨ç†ç³»ç»Ÿï¼ˆä¼˜åŒ–ç‰ˆï¼‰\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶\n",
    "    if not Path(CONFIG['model_path']).exists():\n",
    "        print(f\"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {CONFIG['model_path']}\")\n",
    "        print(f\"ğŸ’¡ æç¤º: è¯·å…ˆè¿è¡Œ train_yolov8_optimized.py è®­ç»ƒæ¨¡å‹\")\n",
    "        return\n",
    "    \n",
    "    # æ£€æŸ¥éªŒè¯é›†ç›®å½•\n",
    "    if not Path(CONFIG['val_img_dir']).exists():\n",
    "        print(f\"âŒ é”™è¯¯: éªŒè¯é›†ç›®å½•ä¸å­˜åœ¨ {CONFIG['val_img_dir']}\")\n",
    "        return\n",
    "    \n",
    "    # åŠ è½½æ¨¡å‹\n",
    "    print(f\"â³ æ­£åœ¨åŠ è½½æ¨¡å‹: {CONFIG['model_path']}\")\n",
    "    model = YOLO(CONFIG['model_path'])\n",
    "    print(f\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!\\n\")\n",
    "    \n",
    "    # æ‰“å°é…ç½®ä¿¡æ¯\n",
    "    print(f\"ğŸ“Š æ¨ç†é…ç½®ï¼ˆå·²ä¼˜åŒ–ï¼‰:\")\n",
    "    print(f\"   å›¾åƒå°ºå¯¸: {CONFIG['img_size']}px\")\n",
    "    print(f\"   ç½®ä¿¡åº¦é˜ˆå€¼: {CONFIG['conf_threshold']} âœ… ä¼˜åŒ–\")\n",
    "    print(f\"   IoUé˜ˆå€¼: {CONFIG['iou_threshold']} âœ… ä¼˜åŒ–\")\n",
    "    print(f\"   TTA: {'å¯ç”¨' if CONFIG['use_tta'] else 'ç¦ç”¨'}\")\n",
    "    if CONFIG['use_tta']:\n",
    "        print(f\"   TTAå°ºåº¦: {CONFIG['tta_scales']} âœ… å¢åŠ \")\n",
    "        print(f\"   TTAç¿»è½¬: {CONFIG['tta_flips']}\")\n",
    "    print()\n",
    "    \n",
    "    # è·å–éªŒè¯é›†å›¾ç‰‡åˆ—è¡¨\n",
    "    val_dir = Path(CONFIG['val_img_dir'])\n",
    "    image_files = list(val_dir.glob(\"*.jpg\")) + \\\n",
    "                  list(val_dir.glob(\"*.png\")) + \\\n",
    "                  list(val_dir.glob(\"*.jpeg\"))\n",
    "    \n",
    "    print(f\"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ éªŒè¯é›†å›¾ç‰‡\\n\")\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"âš ï¸ è­¦å‘Š: éªŒè¯é›†ç›®å½•ä¸ºç©º\")\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # æ¨ç†å¾ªç¯\n",
    "    for img_path in tqdm(image_files, desc=\"ğŸš€ æ¨ç†è¿›è¡Œä¸­\"):\n",
    "        try:\n",
    "            # é€‰æ‹©æ¨ç†æ–¹å¼\n",
    "            if CONFIG['use_tta']:\n",
    "                boxes, scores, labels = predict_with_tta(\n",
    "                    model,\n",
    "                    img_path,\n",
    "                    scales=CONFIG['tta_scales'],\n",
    "                    flips=CONFIG['tta_flips'],\n",
    "                    img_size=CONFIG['img_size'],\n",
    "                    conf_threshold=CONFIG['conf_threshold'],\n",
    "                    iou_threshold=CONFIG['iou_threshold']\n",
    "                )\n",
    "            else:\n",
    "                boxes, scores, labels = predict_standard(\n",
    "                    model,\n",
    "                    img_path,\n",
    "                    img_size=CONFIG['img_size'],\n",
    "                    conf_threshold=CONFIG['conf_threshold'],\n",
    "                    iou_threshold=CONFIG['iou_threshold']\n",
    "                )\n",
    "            \n",
    "            # è½¬æ¢ä¸ºCOCOæ ¼å¼å¹¶ä¿å­˜ç»“æœ\n",
    "            for i in range(len(boxes)):\n",
    "                x1, y1, x2, y2 = boxes[i]\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                \n",
    "                # è½¬æ¢YOLOç±»åˆ«ç´¢å¼•ä¸ºCOCO category_id\n",
    "                coco_category_id = YOLO_TO_COCO.get(int(labels[i]), int(labels[i]))\n",
    "                \n",
    "                results.append({\n",
    "                    \"bbox\": [float(x1), float(y1), float(width), float(height)],\n",
    "                    \"category_id\": coco_category_id,\n",
    "                    \"file_name\": img_path.name,\n",
    "                    \"score\": float(scores[i])\n",
    "                })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸ å¤„ç†å›¾ç‰‡ {img_path.name} æ—¶å‡ºé”™: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # ä¿å­˜æ¨ç†ç»“æœ\n",
    "    print(f\"\\nğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœåˆ° {CONFIG['output_json']} ...\")\n",
    "    with open(CONFIG['output_json'], 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"âœ… æ¨ç†å®Œæˆ!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "    print(f\"   å¤„ç†å›¾ç‰‡æ•°: {len(image_files)}\")\n",
    "    print(f\"   æ€»æ£€æµ‹æ¡†æ•°: {len(results)}\")\n",
    "    \n",
    "    if len(results) > 0:\n",
    "        scores = [r['score'] for r in results]\n",
    "        print(f\"   å¹³å‡ç½®ä¿¡åº¦: {np.mean(scores):.4f}\")\n",
    "        print(f\"   æœ€é«˜ç½®ä¿¡åº¦: {np.max(scores):.4f}\")\n",
    "        print(f\"   æœ€ä½ç½®ä¿¡åº¦: {np.min(scores):.4f}\")\n",
    "        \n",
    "        # æŒ‰ç±»åˆ«ç»Ÿè®¡\n",
    "        category_counts = {}\n",
    "        for r in results:\n",
    "            cat_id = r['category_id']\n",
    "            category_counts[cat_id] = category_counts.get(cat_id, 0) + 1\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:\")\n",
    "        category_names = {1: \"Pothole\", 2: \"Net\"}\n",
    "        for cat_id, count in sorted(category_counts.items()):\n",
    "            cat_name = category_names.get(cat_id, f\"Class {cat_id}\")\n",
    "            percentage = (count / len(results)) * 100\n",
    "            print(f\"   {cat_name}: {count} ä¸ª ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ ç»“æœå·²ä¿å­˜è‡³: {CONFIG['output_json']}\")\n",
    "    print(f\"ğŸ’¡ ä¸‹ä¸€æ­¥: å°† {CONFIG['output_json']} æäº¤åˆ°è¯„æµ‹å¹³å°\")\n",
    "\n",
    "# --- 6. è¿è¡Œå…¥å£ ---\n",
    "if __name__ == \"__main__\":\n",
    "    generate_submission_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04198f5",
   "metadata": {},
   "source": [
    "æœ€å¥½æ¨ç†ä»£ç â€”â€”59.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef2ec7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ High-AP Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462/462 [02:19<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä»»åŠ¡å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ submission_high_ap.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- å¢å¼ºé…ç½® ---\n",
    "CONFIG = {\n",
    "    \"model_paths\": [\n",
    "        \"D:\\\\43420\\\\Desktop\\\\åŒæµå¤§å­¦ç ”ä¸€ä¸Š\\\\äº¤é€šæ•°æ®åˆ†æä¸åº”ç”¨\\\\ç¬¬äºŒæ¬¡ä½œä¸š\\\\è·¯é¢ç—…å®³ä»»åŠ¡æ•°æ®é›†\\\\road_hazard_yolov8_finetune\\\\road_hazard_yolov8_finetune\\\\finetune_v3_unfrozen/weights/best.pt\", \n",
    "        # \"path/to/second_best.pt\" # å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œå¡«åœ¨è¿™é‡Œå®ç° Ensemble\n",
    "    ],\n",
    "    \"val_img_dir\": \"val\",\n",
    "    \"output_json\": \"submission_high_ap.json\",\n",
    "    \"device\": 0,\n",
    "    \n",
    "    # åˆ·åˆ†å…³é”®ï¼šå¤šå°ºåº¦è®¾ç½®\n",
    "    # å¯¹äºå°ç›®æ ‡ï¼Œå¢åŠ  1536 ç”šè‡³ 1920 çš„å°ºåº¦ï¼›å¯¹äºå¤§ç›®æ ‡ï¼Œä¿ç•™ 1280\n",
    "    \"inference_sizes\": [1024, 1280, 1536], \n",
    "    \"conf_threshold\": 0.001,  # åˆ· AP å»ºè®®è®¾åœ¨ 0.001-0.01 ä¹‹é—´ï¼Œå¤ªä½ä¼šå¯¼è‡´æ— æ•ˆæ¡†è¿‡å¤š\n",
    "    \"iou_threshold\": 0.6,    # NMS é˜ˆå€¼\n",
    "    \"use_wbf\": True,         # ä½¿ç”¨ WBF æ›¿ä»£æ™®é€š NMS\n",
    "}\n",
    "\n",
    "YOLO_TO_COCO = {0: 1, 1: 2}\n",
    "\n",
    "def get_predictions(model, img, imgsz, conf, iou):\n",
    "    \"\"\"å•æ¬¡æ¨ç†å°è£…\"\"\"\n",
    "    results = model.predict(\n",
    "        img,\n",
    "        imgsz=imgsz,\n",
    "        conf=conf,\n",
    "        iou=iou,\n",
    "        device=CONFIG['device'],\n",
    "        verbose=False,\n",
    "        augment=True # å¼€å¯ YOLO åŸç”Ÿçš„ç®€å• TTA (Flip/Scale)\n",
    "    )[0]\n",
    "    \n",
    "    if len(results.boxes) == 0:\n",
    "        return None\n",
    "        \n",
    "    return {\n",
    "        \"boxes\": results.boxes.xyxyn.cpu().numpy(), # ä½¿ç”¨å½’ä¸€åŒ–åæ ‡æ–¹ä¾¿ WBF\n",
    "        \"scores\": results.boxes.conf.cpu().numpy(),\n",
    "        \"labels\": results.boxes.cls.cpu().numpy().astype(int)\n",
    "    }\n",
    "\n",
    "def run_advanced_inference():\n",
    "    # 1. åŠ è½½æ‰€æœ‰æ¨¡å‹å®ç°é›†æˆ\n",
    "    models = [YOLO(p) for p in CONFIG['model_paths']]\n",
    "    img_files = list(Path(CONFIG['val_img_dir']).glob(\"*.jpg\"))\n",
    "    \n",
    "    all_results = []\n",
    "\n",
    "    for img_path in tqdm(img_files, desc=\"ğŸ”¥ High-AP Inference\"):\n",
    "        img_cv = cv2.imread(str(img_path))\n",
    "        h, w = img_cv.shape[:2]\n",
    "        \n",
    "        combined_boxes = []\n",
    "        combined_scores = []\n",
    "        combined_labels = []\n",
    "\n",
    "        # 2. å¤šæ¨¡å‹ x å¤šå°ºåº¦ æ¨ç†\n",
    "        for model in models:\n",
    "            for size in CONFIG['inference_sizes']:\n",
    "                pred = get_predictions(model, img_cv, size, CONFIG['conf_threshold'], CONFIG['iou_threshold'])\n",
    "                if pred:\n",
    "                    combined_boxes.append(pred[\"boxes\"])\n",
    "                    combined_scores.append(pred[\"scores\"])\n",
    "                    combined_labels.append(pred[\"labels\"])\n",
    "\n",
    "        if not combined_boxes:\n",
    "            continue\n",
    "\n",
    "        # 3. æ‰§è¡Œ WBF (Weighted Boxes Fusion)\n",
    "        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®‰è£… ensemble_boxes åº“: pip install ensemble-boxes\n",
    "        # å¦‚æœä¸æ–¹ä¾¿å®‰è£…ï¼Œä½¿ç”¨ä½ åŸæœ‰çš„ WBF å‡½æ•°å³å¯\n",
    "        from ensemble_boxes import weighted_boxes_fusion\n",
    "        \n",
    "        # å±•å¹³ list\n",
    "        boxes_list = combined_boxes\n",
    "        scores_list = combined_scores\n",
    "        labels_list = combined_labels\n",
    "        \n",
    "        # WBF å¤„ç†\n",
    "        fused_boxes, fused_scores, fused_labels = weighted_boxes_fusion(\n",
    "            boxes_list, scores_list, labels_list, \n",
    "            weights=None, iou_thr=0.55, skip_box_thr=CONFIG['conf_threshold']\n",
    "        )\n",
    "\n",
    "        # 4. è½¬æ¢å› COCO æ ¼å¼\n",
    "        for i in range(len(fused_boxes)):\n",
    "            x1, y1, x2, y2 = fused_boxes[i]\n",
    "            # è¿˜åŸåæ ‡\n",
    "            x1, x2 = x1 * w, x2 * w\n",
    "            y1, y2 = y1 * h, y2 * h\n",
    "            \n",
    "            all_results.append({\n",
    "                \"file_name\": img_path.name,\n",
    "                \"category_id\": YOLO_TO_COCO.get(int(fused_labels[i]), int(fused_labels[i])),\n",
    "                \"bbox\": [round(float(x1), 2), round(float(y1), 2), \n",
    "                         round(float(x2 - x1), 2), round(float(y2 - y1), 2)],\n",
    "                \"score\": float(fused_scores[i])\n",
    "            })\n",
    "\n",
    "    # 5. ä¿å­˜ç»“æœ\n",
    "    with open(CONFIG['output_json'], 'w') as f:\n",
    "        json.dump(all_results, f)\n",
    "    print(f\"âœ… ä»»åŠ¡å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {CONFIG['output_json']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_advanced_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb18399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ High-AP Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462/462 [04:10<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä»»åŠ¡å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ submission_test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- å¢å¼ºé…ç½® ---\n",
    "CONFIG = {\n",
    "    \"model_paths\": [\n",
    "        \"D:\\\\43420\\\\Desktop\\\\åŒæµå¤§å­¦ç ”ä¸€ä¸Š\\\\äº¤é€šæ•°æ®åˆ†æä¸åº”ç”¨\\\\ç¬¬äºŒæ¬¡ä½œä¸š\\\\è·¯é¢ç—…å®³ä»»åŠ¡æ•°æ®é›†\\\\road_hazard_yolov8_finetune\\\\road_hazard_yolov8_finetune\\\\finetune_v3_unfrozen/weights/best.pt\", \n",
    "        # \"path/to/second_best.pt\" # å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œå¡«åœ¨è¿™é‡Œå®ç° Ensemble\n",
    "    ],\n",
    "    \"val_img_dir\": \"test\",\n",
    "    \"output_json\": \"submission_test.json\",\n",
    "    \"device\": 0,\n",
    "    \n",
    "    # åˆ·åˆ†å…³é”®ï¼šå¤šå°ºåº¦è®¾ç½®\n",
    "    # å¯¹äºå°ç›®æ ‡ï¼Œå¢åŠ  1536 ç”šè‡³ 1920 çš„å°ºåº¦ï¼›å¯¹äºå¤§ç›®æ ‡ï¼Œä¿ç•™ 1280\n",
    "    \"inference_sizes\": [1024, 1280, 1536], \n",
    "    \"conf_threshold\": 0.001,  # åˆ· AP å»ºè®®è®¾åœ¨ 0.001-0.01 ä¹‹é—´ï¼Œå¤ªä½ä¼šå¯¼è‡´æ— æ•ˆæ¡†è¿‡å¤š\n",
    "    \"iou_threshold\": 0.6,    # NMS é˜ˆå€¼\n",
    "    \"use_wbf\": True,         # ä½¿ç”¨ WBF æ›¿ä»£æ™®é€š NMS\n",
    "}\n",
    "\n",
    "YOLO_TO_COCO = {0: 1, 1: 2}\n",
    "\n",
    "def get_predictions(model, img, imgsz, conf, iou):\n",
    "    \"\"\"å•æ¬¡æ¨ç†å°è£…\"\"\"\n",
    "    results = model.predict(\n",
    "        img,\n",
    "        imgsz=imgsz,\n",
    "        conf=conf,\n",
    "        iou=iou,\n",
    "        device=CONFIG['device'],\n",
    "        verbose=False,\n",
    "        augment=True # å¼€å¯ YOLO åŸç”Ÿçš„ç®€å• TTA (Flip/Scale)\n",
    "    )[0]\n",
    "    \n",
    "    if len(results.boxes) == 0:\n",
    "        return None\n",
    "        \n",
    "    return {\n",
    "        \"boxes\": results.boxes.xyxyn.cpu().numpy(), # ä½¿ç”¨å½’ä¸€åŒ–åæ ‡æ–¹ä¾¿ WBF\n",
    "        \"scores\": results.boxes.conf.cpu().numpy(),\n",
    "        \"labels\": results.boxes.cls.cpu().numpy().astype(int)\n",
    "    }\n",
    "\n",
    "def run_advanced_inference():\n",
    "    # 1. åŠ è½½æ‰€æœ‰æ¨¡å‹å®ç°é›†æˆ\n",
    "    models = [YOLO(p) for p in CONFIG['model_paths']]\n",
    "    img_files = list(Path(CONFIG['val_img_dir']).glob(\"*.jpg\"))\n",
    "    \n",
    "    all_results = []\n",
    "\n",
    "    for img_path in tqdm(img_files, desc=\"ğŸ”¥ High-AP Inference\"):\n",
    "        img_cv = cv2.imread(str(img_path))\n",
    "        h, w = img_cv.shape[:2]\n",
    "        \n",
    "        combined_boxes = []\n",
    "        combined_scores = []\n",
    "        combined_labels = []\n",
    "\n",
    "        # 2. å¤šæ¨¡å‹ x å¤šå°ºåº¦ æ¨ç†\n",
    "        for model in models:\n",
    "            for size in CONFIG['inference_sizes']:\n",
    "                pred = get_predictions(model, img_cv, size, CONFIG['conf_threshold'], CONFIG['iou_threshold'])\n",
    "                if pred:\n",
    "                    combined_boxes.append(pred[\"boxes\"])\n",
    "                    combined_scores.append(pred[\"scores\"])\n",
    "                    combined_labels.append(pred[\"labels\"])\n",
    "\n",
    "        if not combined_boxes:\n",
    "            continue\n",
    "\n",
    "        # 3. æ‰§è¡Œ WBF (Weighted Boxes Fusion)\n",
    "        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®‰è£… ensemble_boxes åº“: pip install ensemble-boxes\n",
    "        # å¦‚æœä¸æ–¹ä¾¿å®‰è£…ï¼Œä½¿ç”¨ä½ åŸæœ‰çš„ WBF å‡½æ•°å³å¯\n",
    "        from ensemble_boxes import weighted_boxes_fusion\n",
    "        \n",
    "        # å±•å¹³ list\n",
    "        boxes_list = combined_boxes\n",
    "        scores_list = combined_scores\n",
    "        labels_list = combined_labels\n",
    "        \n",
    "        # WBF å¤„ç†\n",
    "        fused_boxes, fused_scores, fused_labels = weighted_boxes_fusion(\n",
    "            boxes_list, scores_list, labels_list, \n",
    "            weights=None, iou_thr=0.55, skip_box_thr=CONFIG['conf_threshold']\n",
    "        )\n",
    "\n",
    "        # 4. è½¬æ¢å› COCO æ ¼å¼\n",
    "        for i in range(len(fused_boxes)):\n",
    "            x1, y1, x2, y2 = fused_boxes[i]\n",
    "            # è¿˜åŸåæ ‡\n",
    "            x1, x2 = x1 * w, x2 * w\n",
    "            y1, y2 = y1 * h, y2 * h\n",
    "            \n",
    "            all_results.append({\n",
    "                \"file_name\": img_path.name,\n",
    "                \"category_id\": YOLO_TO_COCO.get(int(fused_labels[i]), int(fused_labels[i])),\n",
    "                \"bbox\": [round(float(x1), 2), round(float(y1), 2), \n",
    "                         round(float(x2 - x1), 2), round(float(y2 - y1), 2)],\n",
    "                \"score\": float(fused_scores[i])\n",
    "            })\n",
    "\n",
    "    # 5. ä¿å­˜ç»“æœ\n",
    "    with open(CONFIG['output_json'], 'w') as f:\n",
    "        json.dump(all_results, f)\n",
    "    print(f\"âœ… ä»»åŠ¡å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {CONFIG['output_json']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_advanced_inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1dbc6",
   "metadata": {},
   "source": [
    "æœ€å¥½â€”â€”63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21fe11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ High-AP Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462/462 [07:15<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä»»åŠ¡å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ submission_test1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- å¢å¼ºé…ç½® ---\n",
    "CONFIG = {\n",
    "    \"model_paths\": [\n",
    "        \"D:\\\\43420\\\\Desktop\\\\åŒæµå¤§å­¦ç ”ä¸€ä¸Š\\\\äº¤é€šæ•°æ®åˆ†æä¸åº”ç”¨\\\\ç¬¬äºŒæ¬¡ä½œä¸š\\\\è·¯é¢ç—…å®³ä»»åŠ¡æ•°æ®é›†\\\\road_hazard_yolov8_finetune\\\\road_hazard_yolov8_finetune\\\\finetune_v3_unfrozen/weights/best.pt\", \n",
    "        # \"path/to/second_best.pt\" # å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œå¡«åœ¨è¿™é‡Œå®ç° Ensemble\n",
    "    ],\n",
    "    \"val_img_dir\": \"test\",\n",
    "    \"output_json\": \"submission_test1.json\",\n",
    "    \"device\": 0,\n",
    "    \n",
    "    # åˆ·åˆ†å…³é”®ï¼šå¤šå°ºåº¦è®¾ç½®\n",
    "    # å¯¹äºå°ç›®æ ‡ï¼Œå¢åŠ  1536 ç”šè‡³ 1920 çš„å°ºåº¦ï¼›å¯¹äºå¤§ç›®æ ‡ï¼Œä¿ç•™ 1280\n",
    "    \"inference_sizes\": [1024, 1280, 1536, 1920], \n",
    "    \"conf_threshold\": 0.008,  # åˆ· AP å»ºè®®è®¾åœ¨ 0.001-0.01 ä¹‹é—´ï¼Œå¤ªä½ä¼šå¯¼è‡´æ— æ•ˆæ¡†è¿‡å¤š\n",
    "    \"iou_threshold\": 0.6,    # NMS é˜ˆå€¼\n",
    "    \"use_wbf\": True,         # ä½¿ç”¨ WBF æ›¿ä»£æ™®é€š NMS\n",
    "}\n",
    "\n",
    "YOLO_TO_COCO = {0: 1, 1: 2}\n",
    "\n",
    "def get_predictions(model, img, imgsz, conf, iou):\n",
    "    \"\"\"å•æ¬¡æ¨ç†å°è£…\"\"\"\n",
    "    results = model.predict(\n",
    "        img,\n",
    "        imgsz=imgsz,\n",
    "        conf=conf,\n",
    "        iou=iou,\n",
    "        device=CONFIG['device'],\n",
    "        verbose=False,\n",
    "        augment=True # å¼€å¯ YOLO åŸç”Ÿçš„ç®€å• TTA (Flip/Scale)\n",
    "    )[0]\n",
    "    \n",
    "    if len(results.boxes) == 0:\n",
    "        return None\n",
    "        \n",
    "    return {\n",
    "        \"boxes\": results.boxes.xyxyn.cpu().numpy(), # ä½¿ç”¨å½’ä¸€åŒ–åæ ‡æ–¹ä¾¿ WBF\n",
    "        \"scores\": results.boxes.conf.cpu().numpy(),\n",
    "        \"labels\": results.boxes.cls.cpu().numpy().astype(int)\n",
    "    }\n",
    "\n",
    "def run_advanced_inference():\n",
    "    # 1. åŠ è½½æ‰€æœ‰æ¨¡å‹å®ç°é›†æˆ\n",
    "    models = [YOLO(p) for p in CONFIG['model_paths']]\n",
    "    img_files = list(Path(CONFIG['val_img_dir']).glob(\"*.jpg\"))\n",
    "    \n",
    "    all_results = []\n",
    "\n",
    "    for img_path in tqdm(img_files, desc=\"ğŸ”¥ High-AP Inference\"):\n",
    "        img_cv = cv2.imread(str(img_path))\n",
    "        h, w = img_cv.shape[:2]\n",
    "        \n",
    "        combined_boxes = []\n",
    "        combined_scores = []\n",
    "        combined_labels = []\n",
    "\n",
    "        # 2. å¤šæ¨¡å‹ x å¤šå°ºåº¦ æ¨ç†\n",
    "        for model in models:\n",
    "            for size in CONFIG['inference_sizes']:\n",
    "                pred = get_predictions(model, img_cv, size, CONFIG['conf_threshold'], CONFIG['iou_threshold'])\n",
    "                if pred:\n",
    "                    combined_boxes.append(pred[\"boxes\"])\n",
    "                    combined_scores.append(pred[\"scores\"])\n",
    "                    combined_labels.append(pred[\"labels\"])\n",
    "\n",
    "        if not combined_boxes:\n",
    "            continue\n",
    "\n",
    "        # 3. æ‰§è¡Œ WBF (Weighted Boxes Fusion)\n",
    "        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®‰è£… ensemble_boxes åº“: pip install ensemble-boxes\n",
    "        # å¦‚æœä¸æ–¹ä¾¿å®‰è£…ï¼Œä½¿ç”¨ä½ åŸæœ‰çš„ WBF å‡½æ•°å³å¯\n",
    "        from ensemble_boxes import weighted_boxes_fusion\n",
    "        \n",
    "        # å±•å¹³ list\n",
    "        boxes_list = combined_boxes\n",
    "        scores_list = combined_scores\n",
    "        labels_list = combined_labels\n",
    "        \n",
    "        # WBF å¤„ç†\n",
    "        fused_boxes, fused_scores, fused_labels = weighted_boxes_fusion(\n",
    "            boxes_list, scores_list, labels_list, \n",
    "            weights=None, iou_thr=0.55, skip_box_thr=CONFIG['conf_threshold']\n",
    "        )\n",
    "\n",
    "        # 4. è½¬æ¢å› COCO æ ¼å¼\n",
    "        for i in range(len(fused_boxes)):\n",
    "            x1, y1, x2, y2 = fused_boxes[i]\n",
    "            # è¿˜åŸåæ ‡\n",
    "            x1, x2 = x1 * w, x2 * w\n",
    "            y1, y2 = y1 * h, y2 * h\n",
    "            \n",
    "            all_results.append({\n",
    "                \"file_name\": img_path.name,\n",
    "                \"category_id\": YOLO_TO_COCO.get(int(fused_labels[i]), int(fused_labels[i])),\n",
    "                \"bbox\": [round(float(x1), 2), round(float(y1), 2), \n",
    "                         round(float(x2 - x1), 2), round(float(y2 - y1), 2)],\n",
    "                \"score\": float(fused_scores[i])\n",
    "            })\n",
    "\n",
    "    # 5. ä¿å­˜ç»“æœ\n",
    "    with open(CONFIG['output_json'], 'w') as f:\n",
    "        json.dump(all_results, f)\n",
    "    print(f\"âœ… ä»»åŠ¡å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {CONFIG['output_json']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_advanced_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40a668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ High-AP Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462/462 [13:10<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä»»åŠ¡å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ submission_test2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- å¢å¼ºé…ç½® ---\n",
    "CONFIG = {\n",
    "    \"model_paths\": [\n",
    "        \"D:\\\\43420\\\\Desktop\\\\åŒæµå¤§å­¦ç ”ä¸€ä¸Š\\\\äº¤é€šæ•°æ®åˆ†æä¸åº”ç”¨\\\\ç¬¬äºŒæ¬¡ä½œä¸š\\\\è·¯é¢ç—…å®³ä»»åŠ¡æ•°æ®é›†\\\\road_hazard_yolov8_finetune\\\\road_hazard_yolov8_finetune\\\\finetune_v3_unfrozen/weights/best.pt\", \n",
    "        \"D:\\\\43420\\\\Desktop\\\\åŒæµå¤§å­¦ç ”ä¸€ä¸Š\\\\äº¤é€šæ•°æ®åˆ†æä¸åº”ç”¨\\\\ç¬¬äºŒæ¬¡ä½œä¸š\\\\è·¯é¢ç—…å®³ä»»åŠ¡æ•°æ®é›†\\\\road_hazard_yolov8_finetune\\\\road_hazard_yolov8_finetune\\\\finetune_v4_unfrozen/weights/best.pt\" # å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œå¡«åœ¨è¿™é‡Œå®ç° Ensemble\n",
    "    ],\n",
    "    \"val_img_dir\": \"test\",\n",
    "    \"output_json\": \"submission_test2.json\",\n",
    "    \"device\": 0,\n",
    "    \n",
    "    # åˆ·åˆ†å…³é”®ï¼šå¤šå°ºåº¦è®¾ç½®\n",
    "    # å¯¹äºå°ç›®æ ‡ï¼Œå¢åŠ  1536 ç”šè‡³ 1920 çš„å°ºåº¦ï¼›å¯¹äºå¤§ç›®æ ‡ï¼Œä¿ç•™ 1280\n",
    "    \"inference_sizes\": [1024, 1280, 1536, 1920], \n",
    "    \"conf_threshold\": 0.008,  # åˆ· AP å»ºè®®è®¾åœ¨ 0.001-0.01 ä¹‹é—´ï¼Œå¤ªä½ä¼šå¯¼è‡´æ— æ•ˆæ¡†è¿‡å¤š\n",
    "    \"iou_threshold\": 0.6,    # NMS é˜ˆå€¼\n",
    "    \"use_wbf\": True,         # ä½¿ç”¨ WBF æ›¿ä»£æ™®é€š NMS\n",
    "}\n",
    "\n",
    "YOLO_TO_COCO = {0: 1, 1: 2}\n",
    "\n",
    "def get_predictions(model, img, imgsz, conf, iou):\n",
    "    \"\"\"å•æ¬¡æ¨ç†å°è£…\"\"\"\n",
    "    results = model.predict(\n",
    "        img,\n",
    "        imgsz=imgsz,\n",
    "        conf=conf,\n",
    "        iou=iou,\n",
    "        device=CONFIG['device'],\n",
    "        verbose=False,\n",
    "        augment=True # å¼€å¯ YOLO åŸç”Ÿçš„ç®€å• TTA (Flip/Scale)\n",
    "    )[0]\n",
    "    \n",
    "    if len(results.boxes) == 0:\n",
    "        return None\n",
    "        \n",
    "    return {\n",
    "        \"boxes\": results.boxes.xyxyn.cpu().numpy(), # ä½¿ç”¨å½’ä¸€åŒ–åæ ‡æ–¹ä¾¿ WBF\n",
    "        \"scores\": results.boxes.conf.cpu().numpy(),\n",
    "        \"labels\": results.boxes.cls.cpu().numpy().astype(int)\n",
    "    }\n",
    "\n",
    "def run_advanced_inference():\n",
    "    # 1. åŠ è½½æ‰€æœ‰æ¨¡å‹å®ç°é›†æˆ\n",
    "    models = [YOLO(p) for p in CONFIG['model_paths']]\n",
    "    img_files = list(Path(CONFIG['val_img_dir']).glob(\"*.jpg\"))\n",
    "    \n",
    "    all_results = []\n",
    "\n",
    "    for img_path in tqdm(img_files, desc=\"ğŸ”¥ High-AP Inference\"):\n",
    "        img_cv = cv2.imread(str(img_path))\n",
    "        h, w = img_cv.shape[:2]\n",
    "        \n",
    "        combined_boxes = []\n",
    "        combined_scores = []\n",
    "        combined_labels = []\n",
    "\n",
    "        # 2. å¤šæ¨¡å‹ x å¤šå°ºåº¦ æ¨ç†\n",
    "        for model in models:\n",
    "            for size in CONFIG['inference_sizes']:\n",
    "                pred = get_predictions(model, img_cv, size, CONFIG['conf_threshold'], CONFIG['iou_threshold'])\n",
    "                if pred:\n",
    "                    combined_boxes.append(pred[\"boxes\"])\n",
    "                    combined_scores.append(pred[\"scores\"])\n",
    "                    combined_labels.append(pred[\"labels\"])\n",
    "\n",
    "        if not combined_boxes:\n",
    "            continue\n",
    "\n",
    "        # 3. æ‰§è¡Œ WBF (Weighted Boxes Fusion)\n",
    "        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®‰è£… ensemble_boxes åº“: pip install ensemble-boxes\n",
    "        # å¦‚æœä¸æ–¹ä¾¿å®‰è£…ï¼Œä½¿ç”¨ä½ åŸæœ‰çš„ WBF å‡½æ•°å³å¯\n",
    "        from ensemble_boxes import weighted_boxes_fusion\n",
    "        \n",
    "        # å±•å¹³ list\n",
    "        boxes_list = combined_boxes\n",
    "        scores_list = combined_scores\n",
    "        labels_list = combined_labels\n",
    "        \n",
    "        # WBF å¤„ç†\n",
    "        fused_boxes, fused_scores, fused_labels = weighted_boxes_fusion(\n",
    "            boxes_list, scores_list, labels_list, \n",
    "            weights=None, iou_thr=0.55, skip_box_thr=CONFIG['conf_threshold']\n",
    "        )\n",
    "\n",
    "        # 4. è½¬æ¢å› COCO æ ¼å¼\n",
    "        for i in range(len(fused_boxes)):\n",
    "            x1, y1, x2, y2 = fused_boxes[i]\n",
    "            # è¿˜åŸåæ ‡\n",
    "            x1, x2 = x1 * w, x2 * w\n",
    "            y1, y2 = y1 * h, y2 * h\n",
    "            \n",
    "            all_results.append({\n",
    "                \"file_name\": img_path.name,\n",
    "                \"category_id\": YOLO_TO_COCO.get(int(fused_labels[i]), int(fused_labels[i])),\n",
    "                \"bbox\": [round(float(x1), 2), round(float(y1), 2), \n",
    "                         round(float(x2 - x1), 2), round(float(y2 - y1), 2)],\n",
    "                \"score\": float(fused_scores[i])\n",
    "            })\n",
    "\n",
    "    # 5. ä¿å­˜ç»“æœ\n",
    "    with open(CONFIG['output_json'], 'w') as f:\n",
    "        json.dump(all_results, f)\n",
    "    print(f\"âœ… ä»»åŠ¡å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {CONFIG['output_json']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_advanced_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba29bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“Š æ•°æ®é›†æ·±åº¦åˆ†æ\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:\n",
      "   Net(id=2): 2720 ä¸ª (66.49%)\n",
      "   Pothole(id=1): 1371 ä¸ª (33.51%)\n",
      "\n",
      "ğŸ“ è¾¹ç•Œæ¡†ç»Ÿè®¡:\n",
      "   å¹³å‡é¢ç§¯: 76206.92 pxÂ²\n",
      "   ä¸­ä½æ•°é¢ç§¯: 30561.00 pxÂ²\n",
      "   æœ€å°é¢ç§¯: 297.00 pxÂ²\n",
      "   æœ€å¤§é¢ç§¯: 1511040.00 pxÂ²\n",
      "   å¹³å‡å®½é«˜æ¯”: 2.17\n",
      "\n",
      "ğŸ¯ ç›®æ ‡å°ºåº¦åˆ†å¸ƒ:\n",
      "   å°ç›®æ ‡(<32px): 327 (7.99%)\n",
      "   ä¸­ç›®æ ‡(32-96px): 1017 (24.86%)\n",
      "   å¤§ç›®æ ‡(>96px): 2747 (67.15%)\n",
      "\n",
      "ğŸ–¼ï¸ æ¯å¼ å›¾ç‰‡çš„æ ‡æ³¨æ•°:\n",
      "   å¹³å‡: 1.36\n",
      "   ä¸­ä½æ•°: 1\n",
      "   æœ€å¤§: 10\n",
      "   æ— æ ‡æ³¨å›¾ç‰‡: 0\n",
      "\n",
      "======================================================================\n",
      "ğŸ’¡ ä¼˜åŒ–å»ºè®®:\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_dataset(json_path, img_dir):\n",
    "    \"\"\"æ·±åº¦åˆ†ææ•°æ®é›†ç‰¹å¾\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ“Š æ•°æ®é›†æ·±åº¦åˆ†æ\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 1. ç±»åˆ«åˆ†å¸ƒ\n",
    "    categories = [ann['category_id'] for ann in data['annotations']]\n",
    "    cat_counts = Counter(categories)\n",
    "    print(f\"ğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:\")\n",
    "    for cat_id, count in cat_counts.items():\n",
    "        cat_name = \"Pothole\" if cat_id == 1 else \"Net\"\n",
    "        print(f\"   {cat_name}(id={cat_id}): {count} ä¸ª ({count/len(categories)*100:.2f}%)\")\n",
    "    \n",
    "    # 2. è¾¹ç•Œæ¡†å°ºå¯¸åˆ†æ\n",
    "    bbox_areas = []\n",
    "    bbox_aspect_ratios = []\n",
    "    for ann in data['annotations']:\n",
    "        w, h = ann['bbox'][2], ann['bbox'][3]\n",
    "        bbox_areas.append(w * h)\n",
    "        bbox_aspect_ratios.append(w / (h + 1e-6))\n",
    "    \n",
    "    print(f\"\\nğŸ“ è¾¹ç•Œæ¡†ç»Ÿè®¡:\")\n",
    "    print(f\"   å¹³å‡é¢ç§¯: {np.mean(bbox_areas):.2f} pxÂ²\")\n",
    "    print(f\"   ä¸­ä½æ•°é¢ç§¯: {np.median(bbox_areas):.2f} pxÂ²\")\n",
    "    print(f\"   æœ€å°é¢ç§¯: {np.min(bbox_areas):.2f} pxÂ²\")\n",
    "    print(f\"   æœ€å¤§é¢ç§¯: {np.max(bbox_areas):.2f} pxÂ²\")\n",
    "    print(f\"   å¹³å‡å®½é«˜æ¯”: {np.mean(bbox_aspect_ratios):.2f}\")\n",
    "    \n",
    "    # 3. å°ç›®æ ‡å æ¯”ï¼ˆCOCOå®šä¹‰ï¼šé¢ç§¯<32Â²=1024ï¼‰\n",
    "    small_obj_count = sum(1 for area in bbox_areas if area < 1024)\n",
    "    medium_obj_count = sum(1 for area in bbox_areas if 1024 <= area < 96**2)\n",
    "    large_obj_count = sum(1 for area in bbox_areas if area >= 96**2)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ç›®æ ‡å°ºåº¦åˆ†å¸ƒ:\")\n",
    "    print(f\"   å°ç›®æ ‡(<32px): {small_obj_count} ({small_obj_count/len(bbox_areas)*100:.2f}%)\")\n",
    "    print(f\"   ä¸­ç›®æ ‡(32-96px): {medium_obj_count} ({medium_obj_count/len(bbox_areas)*100:.2f}%)\")\n",
    "    print(f\"   å¤§ç›®æ ‡(>96px): {large_obj_count} ({large_obj_count/len(bbox_areas)*100:.2f}%)\")\n",
    "    \n",
    "    # 4. æ¯å¼ å›¾ç‰‡çš„æ ‡æ³¨æ•°é‡\n",
    "    img_to_anns = {}\n",
    "    for ann in data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        img_to_anns[img_id] = img_to_anns.get(img_id, 0) + 1\n",
    "    \n",
    "    ann_counts = list(img_to_anns.values())\n",
    "    print(f\"\\nğŸ–¼ï¸ æ¯å¼ å›¾ç‰‡çš„æ ‡æ³¨æ•°:\")\n",
    "    print(f\"   å¹³å‡: {np.mean(ann_counts):.2f}\")\n",
    "    print(f\"   ä¸­ä½æ•°: {np.median(ann_counts):.0f}\")\n",
    "    print(f\"   æœ€å¤§: {max(ann_counts)}\")\n",
    "    print(f\"   æ— æ ‡æ³¨å›¾ç‰‡: {len(data['images']) - len(img_to_anns)}\")\n",
    "    \n",
    "    return {\n",
    "        'class_imbalance': max(cat_counts.values()) / min(cat_counts.values()),\n",
    "        'small_obj_ratio': small_obj_count / len(bbox_areas),\n",
    "        'avg_bbox_area': np.mean(bbox_areas)\n",
    "    }\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "if __name__ == \"__main__\":\n",
    "    stats = analyze_dataset(\"train.json\", \"train\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ’¡ ä¼˜åŒ–å»ºè®®:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if stats['class_imbalance'] > 3:\n",
    "        print(f\"âš ï¸ ç±»åˆ«ä¸¥é‡ä¸å¹³è¡¡ (æ¯”ä¾‹{stats['class_imbalance']:.1f}:1)\")\n",
    "        print(f\"   â†’ ä½¿ç”¨ç±»åˆ«åŠ æƒæŸå¤±\")\n",
    "    \n",
    "    if stats['small_obj_ratio'] > 0.5:\n",
    "        print(f\"âš ï¸ å°ç›®æ ‡å æ¯”é«˜ ({stats['small_obj_ratio']*100:.1f}%)\")\n",
    "        print(f\"   â†’ ä½¿ç”¨å¤šå°ºåº¦è®­ç»ƒ\")\n",
    "        print(f\"   â†’ å¢å¤§è¾“å…¥å°ºå¯¸åˆ°1920\")\n",
    "    \n",
    "    if stats['avg_bbox_area'] < 2000:\n",
    "        print(f\"âš ï¸ ç›®æ ‡æ™®éè¾ƒå° (å¹³å‡{stats['avg_bbox_area']:.0f}pxÂ²)\")\n",
    "        print(f\"   â†’ å…³é—­Mosaicå¢å¼º\")\n",
    "        print(f\"   â†’ å‡å°éšæœºè£å‰ª\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
